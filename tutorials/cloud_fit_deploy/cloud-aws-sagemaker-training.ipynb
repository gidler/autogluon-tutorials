{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f49b8e7",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gidler/autogluon-tutorials/blob/main/tutorials/cloud_fit_deploy/cloud-aws-sagemaker-training.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/gidler/autogluon-tutorials/blob/main/tutorials/cloud_fit_deploy/cloud-aws-sagemaker-training.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9361a4",
   "outputs": [],
   "metadata": {},
   "source": [
    "# Uncomment the code below and run this cell if AutoGluon is not yet installed in the kernel.\n",
    "# !pip install autogluon==0.5.0  # These tutorials are based on AutoGluon v0.5.0 and might not work with different versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083d2099",
   "metadata": {},
   "source": [
    "# Cloud Training with AWS SageMaker\n",
    "\n",
    "\n",
    "\n",
    "To help with AutoGluon models training, AWS developed a set of training and inference [deep learning containers](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#autogluon-training-containers). \n",
    "The containers can be used to train models with CPU and GPU instances and deployed as a SageMaker endpoint or used as a batch transform job.\n",
    "\n",
    "The full end-to-end example is available in [amazon-sagemaker-examples](https://github.com/aws/amazon-sagemaker-examples/tree/master/advanced_functionality/autogluon-tabular-containers) repository.\n",
    "\n",
    "## Pre-requisites\n",
    "Before starting ensure that the latest version of sagemaker python API is installed via (`pip install --upgrade sagemaker`). \n",
    "This is required to ensure the information about newly released containers is available.\n",
    "\n",
    "## Training Scripts\n",
    "\n",
    "To start using the containers, a user training script and the [wrapper classes](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/autogluon-tabular-containers/ag_model.py) are required.\n",
    "When authoring a training/inference [scripts](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/autogluon-tabular-containers/scripts/), \n",
    "please refer to SageMaker [documentation](https://sagemaker.readthedocs.io/en/stable/overview.html#prepare-a-training-script).\n",
    "\n",
    "Here is one of the possible training scripts, which takes AutoGluon parameters as a YAML config and outputs predictions, models leaderboard and feature importance:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee38690",
   "metadata": {},
   "source": [
    "```{.python}\n",
    "import argparse\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import yaml\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "\n",
    "def get_input_path(path):\n",
    "    file = os.listdir(path)[0]\n",
    "    if len(os.listdir(path)) > 1:\n",
    "        print(f\"WARN: more than one file is found in {channel} directory\")\n",
    "    print(f\"Using {file}\")\n",
    "    filename = f\"{path}/{file}\"\n",
    "    return filename\n",
    "\n",
    "\n",
    "def get_env_if_present(name):\n",
    "    result = None\n",
    "    if name in os.environ:\n",
    "        result = os.environ[name]\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Disable Autotune\n",
    "    os.environ[\"MXNET_CUDNN_AUTOTUNE_DEFAULT\"] = \"0\"\n",
    "\n",
    "    # ------------------------------------------------------------ Arguments parsing\n",
    "    print(\"Starting AG\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\n",
    "        \"--output-data-dir\", type=str, default=get_env_if_present(\"SM_OUTPUT_DATA_DIR\")\n",
    "    )\n",
    "    parser.add_argument(\"--model-dir\", type=str, default=get_env_if_present(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--n_gpus\", type=str, default=get_env_if_present(\"SM_NUM_GPUS\"))\n",
    "    parser.add_argument(\"--training_dir\", type=str, default=get_env_if_present(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\n",
    "        \"--test_dir\", type=str, required=False, default=get_env_if_present(\"SM_CHANNEL_TEST\")\n",
    "    )\n",
    "    parser.add_argument(\"--ag_config\", type=str, default=get_env_if_present(\"SM_CHANNEL_CONFIG\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    print(f\"Args: {args}\")\n",
    "\n",
    "    # See SageMaker-specific environment variables: https://sagemaker.readthedocs.io/en/stable/overview.html#prepare-a-training-script\n",
    "    os.makedirs(args.output_data_dir, mode=0o777, exist_ok=True)\n",
    "\n",
    "    config_file = get_input_path(args.ag_config)\n",
    "    with open(config_file) as f:\n",
    "        config = yaml.safe_load(f)  # AutoGluon-specific config\n",
    "\n",
    "    if args.n_gpus:\n",
    "        config[\"num_gpus\"] = int(args.n_gpus)\n",
    "\n",
    "    print(\"Running training job with the config:\")\n",
    "    pprint(config)\n",
    "\n",
    "    # ---------------------------------------------------------------- Training\n",
    "\n",
    "    train_file = get_input_path(args.training_dir)\n",
    "    train_data = TabularDataset(train_file)\n",
    "\n",
    "    ag_predictor_args = config[\"ag_predictor_args\"]\n",
    "    ag_predictor_args[\"path\"] = args.model_dir\n",
    "    ag_fit_args = config[\"ag_fit_args\"]\n",
    "\n",
    "    predictor = TabularPredictor(**ag_predictor_args).fit(train_data, **ag_fit_args)\n",
    "\n",
    "    # --------------------------------------------------------------- Inference\n",
    "\n",
    "    if args.test_dir:\n",
    "        test_file = get_input_path(args.test_dir)\n",
    "        test_data = TabularDataset(test_file)\n",
    "\n",
    "        # Predictions\n",
    "        y_pred_proba = predictor.predict_proba(test_data)\n",
    "        if config.get(\"output_prediction_format\", \"csv\") == \"parquet\":\n",
    "            y_pred_proba.to_parquet(f\"{args.output_data_dir}/predictions.parquet\")\n",
    "        else:\n",
    "            y_pred_proba.to_csv(f\"{args.output_data_dir}/predictions.csv\")\n",
    "\n",
    "        # Leaderboard\n",
    "        if config.get(\"leaderboard\", False):\n",
    "            lb = predictor.leaderboard(test_data, silent=False)\n",
    "            lb.to_csv(f\"{args.output_data_dir}/leaderboard.csv\")\n",
    "\n",
    "        # Feature importance\n",
    "        if config.get(\"feature_importance\", False):\n",
    "            feature_importance = predictor.feature_importance(test_data)\n",
    "            feature_importance.to_csv(f\"{args.output_data_dir}/feature_importance.csv\")\n",
    "    else:\n",
    "        if config.get(\"leaderboard\", False):\n",
    "            lb = predictor.leaderboard(silent=False)\n",
    "            lb.to_csv(f\"{args.output_data_dir}/leaderboard.csv\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2983390c",
   "metadata": {},
   "source": [
    "YAML config:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026aa10e",
   "metadata": {},
   "source": [
    "```yaml\n",
    "# AutoGluon Predictor constructor arguments\n",
    "# - see https://github.com/awslabs/autogluon/blob/ef3a5312dc2eaa0c6afde042d671860ac42cbafb/tabular/src/autogluon/tabular/predictor/predictor.py#L51-L159\n",
    "ag_predictor_args:\n",
    "  eval_metric: roc_auc\n",
    "  label: class\n",
    "\n",
    "# AutoGluon Predictor.fit arguments\n",
    "# - see https://github.com/awslabs/autogluon/blob/ef3a5312dc2eaa0c6afde042d671860ac42cbafb/tabular/src/autogluon/tabular/predictor/predictor.py#L280-L651\n",
    "ag_fit_args:\n",
    "  presets: \"medium_quality_faster_train\"\n",
    "  num_bag_folds: 2\n",
    "  num_bag_sets: 1\n",
    "  num_stack_levels: 0\n",
    "\n",
    "output_prediction_format: csv  # predictions output format: csv or parquet\n",
    "feature_importance: true       # calculate and save feature importance if true\n",
    "leaderboard: true              # save leaderboard output if true\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08748b8",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "To train AutoGluon model, set up a SageMaker session:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f8c3f6",
   "metadata": {},
   "source": [
    "```{.python}\n",
    "import sagemaker\n",
    "\n",
    "# Helper wrappers referred earlier\n",
    "from ag_model import (\n",
    "    AutoGluonTraining,\n",
    "    AutoGluonInferenceModel,\n",
    "    AutoGluonTabularPredictor,\n",
    ")\n",
    "from sagemaker import utils\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "region = sagemaker_session._region_name\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "s3_prefix = f\"autogluon_sm/{utils.sagemaker_timestamp()}\"\n",
    "output_path = f\"s3://{bucket}/{s3_prefix}/output/\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef9047",
   "metadata": {},
   "source": [
    "Create a training task:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff27fcf5",
   "metadata": {},
   "source": [
    "```{.python}\n",
    "ag = AutoGluonTraining(\n",
    "    role=role,\n",
    "    entry_point=\"scripts/tabular_train.py\",\n",
    "    region=region,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.2xlarge\",\n",
    "    framework_version=\"0.4\",\n",
    "    py_version=\"py38\",\n",
    "    base_job_name=\"autogluon-tabular-train\",\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2667a26b",
   "metadata": {},
   "source": [
    "Upload the required inputs, via SageMaker session (in this case it is a training set, test set and training YAML config) and start the training job:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf994ed8",
   "metadata": {},
   "source": [
    "```{.python}\n",
    "s3_prefix = f\"autogluon_sm/{utils.sagemaker_timestamp()}\"\n",
    "train_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"data\", \"train.csv\"), key_prefix=s3_prefix\n",
    ")\n",
    "eval_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"data\", \"test.csv\"), key_prefix=s3_prefix\n",
    ")\n",
    "config_input = ag.sagemaker_session.upload_data(\n",
    "    path=os.path.join(\"config\", \"config-med.yaml\"), key_prefix=s3_prefix\n",
    ")\n",
    "\n",
    "job_name = utils.unique_name_from_base(\"test-autogluon-image\")\n",
    "ag.fit(\n",
    "    {\"config\": config_input, \"train\": train_input, \"test\": eval_input},\n",
    "    job_name=job_name,\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705a25a8",
   "metadata": {},
   "source": [
    "Once the models are trained, they will be available in S3 location specified in `ag.model_data` field. The model is fully portable and can be downloaded locally\n",
    "if needed.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this tutorial we explored how to train AutoGluon models using SageMaker. Learn how to deploy the trained models using \n",
    "AWS SageMaker - [tutorials/cloud_fit_deploy/cloud-aws-sagemaker-deployment.ipynb](https://github.com/gidler/autogluon-tutorials/blob/main/tutorials/cloud_fit_deploy/cloud-aws-sagemaker-deployment.ipynb) or AWS Lambda - [tutorials/cloud_fit_deploy/cloud-aws-lambda-deployment.ipynb](https://github.com/gidler/autogluon-tutorials/blob/main/tutorials/cloud_fit_deploy/cloud-aws-lambda-deployment.ipynb)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}