{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278aca48",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gidler/autogluon-tutorials/blob/main/tutorials/multimodal/beginner_image_cls.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/gidler/autogluon-tutorials/blob/main/tutorials/multimodal/beginner_image_cls.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4e26ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the code below and run this cell if AutoGluon is not yet installed in the kernel.\n",
    "# !pip install autogluon==0.5.2  # These tutorials are based on AutoGluon v0.5.2 and might not work with different versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ea9618",
   "metadata": {},
   "source": [
    "# AutoMM for Image Classification - Quick Start\n",
    "\n",
    "\n",
    "\n",
    "In this quick start, we'll use the task of image classification to illustrate how to use **MultiModalPredictor**. Once the data is prepared in [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) format, a single call to `MultiModalPredictor.fit()` will take care of the model training for you.\n",
    "\n",
    "\n",
    "## Create Image Dataset\n",
    "\n",
    "For demonstration purposes, we use a subset of the [Shopee-IET dataset](https://www.kaggle.com/c/shopee-iet-machine-learning-competition/data) from Kaggle.\n",
    "Each image in this data depicts a clothing item and the corresponding label specifies its clothing category.\n",
    "Our subset of the data contains the following possible labels: `BabyPants`, `BabyShirt`, `womencasualshoes`, `womenchiffontop`.\n",
    "\n",
    "We can load a dataset by downloading a url data automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8115bf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from autogluon.vision import ImageDataset\n",
    "train_dataset, _, test_dataset = ImageDataset.from_folders(\"https://autogluon.s3.amazonaws.com/datasets/shopee-iet.zip\")\n",
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac280f3c",
   "metadata": {},
   "source": [
    "We can see there are 800 rows and 2 columns in this training dataframe. The 2 columns are **image** and **label**, and each row represents a different training sample.\n",
    "\n",
    "\n",
    "## Use AutoMM to Fit Models\n",
    "\n",
    "Now, we fit a classifier using AutoMM as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf69e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "predictor = MultiModalPredictor(label=\"label\", path=\"./automm_imgcls\")\n",
    "predictor.fit(\n",
    "    train_data=train_dataset,\n",
    "    time_limit=30, # seconds\n",
    ") # you can trust the default config, e.g., we use a `swin_base_patch4_window7_224` model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d654be6",
   "metadata": {},
   "source": [
    "**label** is the name of the column that contains the target variable to predict, e.g., it is \"label\" in our example. **path** indicates the directory where models and intermediate outputs should be saved. We set the training time limit to 30 seconds for demonstration purpose, but you can control the training time by setting configurations. To customize AutoMM, please refer to [tutorials/multimodal/customization.ipynb](https://github.com/gidler/autogluon-tutorials/blob/main/tutorials/multimodal/customization.ipynb).\n",
    "\n",
    "\n",
    "## Evaluate on Test Dataset\n",
    "\n",
    "You can evaluate the classifier on the test dataset to see how it performs, the test top-1 accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd75505",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = predictor.evaluate(test_dataset, metrics=[\"accuracy\"])\n",
    "print('Top-1 test acc: %.3f' % scores[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819288d",
   "metadata": {},
   "source": [
    "## Predict on a New Image\n",
    "\n",
    "Given an example image, let's visualize it first,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8ec5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = test_dataset.iloc[0]['image']\n",
    "from IPython.display import Image, display\n",
    "pil_img = Image(filename=image_path)\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427ffda1",
   "metadata": {},
   "source": [
    "We can easily use the final model to `predict` the label,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5546c8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict({'image': [image_path]})\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95228f30",
   "metadata": {},
   "source": [
    "If probabilities of all categories are needed, you can call `predict_proba`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e9ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = predictor.predict_proba({'image': [image_path]})\n",
    "print(proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510f3a5c",
   "metadata": {},
   "source": [
    "## Extract Embeddings\n",
    "\n",
    "Extracting representation from the whole image learned by a model is also very useful. We provide `extract_embedding` function to allow predictor to return the N-dimensional image feature where `N` depends on the model(usually a 512 to 2048 length vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b673aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = predictor.extract_embedding({'image': [image_path]})\n",
    "print(feature[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a57b965",
   "metadata": {},
   "source": [
    "## Save and Load\n",
    "\n",
    "The trained predictor is automatically saved at the end of `fit()`, and you can easily reload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67f508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_predictor = MultiModalPredictor.load('automm_imgcls')\n",
    "load_proba = loaded_predictor.predict_proba({'image': [image_path]})\n",
    "print(load_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1bd765",
   "metadata": {},
   "source": [
    "We can see the predicted class probabilities are still the same as above, which means same model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fef73a8",
   "metadata": {},
   "source": [
    "## Other Examples\n",
    "\n",
    "You may go to [AutoMM Examples](https://github.com/awslabs/autogluon/tree/master/examples/automm) to explore other examples about AutoMM.\n",
    "\n",
    "## Customization\n",
    "To learn how to custom AutoMM, please refer to [tutorials/multimodal/customization.ipynb](https://github.com/gidler/autogluon-tutorials/blob/main/tutorials/multimodal/customization.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('ag_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0653dfff7333573d9fbf16a74134d166c986921740aafebc8debea4285acbf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
