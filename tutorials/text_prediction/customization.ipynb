{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1dcc85c",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/gidler/autogluon-tutorials/blob/main/tutorials/text_prediction/customization.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/gidler/autogluon-tutorials/blob/main/tutorials/text_prediction/customization.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b106f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the code below and run this cell if AutoGluon is not yet installed in the kernel.\n",
    "# !pip install autogluon==0.5.2  # These tutorials are based on AutoGluon v0.5.2 and might not work with different versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258f5664",
   "metadata": {},
   "source": [
    "# Text Prediction - Customization\n",
    "\n",
    "\n",
    "\n",
    "This tutorial introduces the presets of `TextPredictor` and how to customize hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f1211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import autogluon as ag\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa38abc0",
   "metadata": {},
   "source": [
    "## Stanford Sentiment Treebank Data\n",
    "\n",
    "For demonstration, we use the Stanford Sentiment Treebank ([SST](https://nlp.stanford.edu/sentiment/)) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be55dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.core import TabularDataset\n",
    "subsample_size = 1000  # subsample for faster demo, you may try specifying larger value\n",
    "train_data = TabularDataset(\"https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/train.parquet\")\n",
    "test_data = TabularDataset(\"https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/dev.parquet\")\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c656baab",
   "metadata": {},
   "source": [
    "## Configure TextPredictor\n",
    "\n",
    "### Preset Configurations\n",
    "\n",
    "`TextPredictor` provides several simple preset configurations. Let's take a look at the available presets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0de8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.text.text_prediction.presets import list_text_presets\n",
    "list_text_presets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44951e0c",
   "metadata": {},
   "source": [
    "You may be interested in the configuration differences behind the preset strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6d410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_text_presets(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24f98ca",
   "metadata": {},
   "source": [
    "We can find that the main difference between different presets lie in the choices of Huggingface transformer checkpoints. Preset `default` has the same configuration as preset `high_quality`. Designing the presets follows the rule of thumb that larger backbones tend to have better performance but with higher cost.\n",
    "\n",
    "Let's train a text predictor with preset `medium_quality_faster_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667de396",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.text import TextPredictor\n",
    "predictor = TextPredictor(eval_metric=\"acc\", label=\"label\")\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    presets=\"medium_quality_faster_train\",\n",
    "    time_limit=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366bbe71",
   "metadata": {},
   "source": [
    "Below we report both `f1` and `acc` metrics for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9da160",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate(test_data, metrics=[\"f1\", \"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f4977",
   "metadata": {},
   "source": [
    "The pre-registered configurations provide reasonable default hyperparameters. A common workflow is to first train a model with one of the presets and then tune some hyperparameters to see if the performance can be further improved.\n",
    "\n",
    "### Customize Hyperparameters\n",
    "\n",
    "Customizing hyperparameters is easy for `TextPredictor`. For example, you may want to try backbones beyond those in the presets. Since `TextPredictor` supports loading Huggingface transformers, you can choose any desired text backbones in the [Hugginface model zoo](https://huggingface.co/models), e.g., `prajjwal1/bert-tiny`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a43df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.text import TextPredictor\n",
    "predictor = TextPredictor(eval_metric=\"acc\", label=\"label\")\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    hyperparameters={\n",
    "        \"model.hf_text.checkpoint_name\": \"prajjwal1/bert-tiny\",\n",
    "    },\n",
    "    time_limit=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897b6c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate(test_data, metrics=[\"f1\", \"acc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c5ff97",
   "metadata": {},
   "source": [
    "`TextPredictor` also supports using the models that are not available in the [Huggingface model zoo](https://huggingface.co/models). To do this, you need to make sure that the models' definition follow Hugginface's AutoModel, AutoConfig, and AutoTokenizer. Let's simulate a local model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1c6258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "model_key = 'prajjwal1/bert-tiny'\n",
    "local_path = 'custom_local_bert_tiny'\n",
    "\n",
    "model = AutoModel.from_pretrained(model_key)\n",
    "config = AutoConfig.from_pretrained(model_key)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_key)\n",
    "\n",
    "model.save_pretrained(local_path)\n",
    "config.save_pretrained(local_path)\n",
    "tokenizer.save_pretrained(local_path)\n",
    "os.listdir(local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5116a0d0",
   "metadata": {},
   "source": [
    "Now we can use this local model in `TextPredictor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7b90f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.text import TextPredictor\n",
    "predictor = TextPredictor(eval_metric=\"acc\", label=\"label\")\n",
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    hyperparameters={\n",
    "        \"model.hf_text.checkpoint_name\": \"custom_local_bert_tiny/\",\n",
    "    },\n",
    "    time_limit=60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc2937",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.evaluate(test_data, metrics=[\"f1\", \"acc\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
